{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Hey everyone! Here's the 'solved' version of this colab notebook, hopefully you can step through this, see how it works, and upload a copy of a working version onto your L645 github fork.\n",
        "\n",
        "Note this notebook was taken and edited from this blog post by Loren Lugosch - and a lot of the PDF was written from what Loren wrote. Take a look at it here if you would like more intuition about the RNN Transducer.\n",
        "https://lorenlugosch.github.io/posts/2020/11/transducer/"
      ],
      "metadata": {
        "id": "lhf01H9AAxwn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbwgR5UdNkkm"
      },
      "source": [
        "# Transducer implementation in PyTorch\n",
        "\n",
        "*by Loren Lugosch*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZWtKmWHEZ5fe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBlJNKsjTtaZ"
      },
      "source": [
        "\n",
        "In this notebook, we will implement a Transducer sequence-to-sequence model for inserting missing vowels into a sentence \n",
        "\n",
        "EX: (\"W wll mplmnt sm cd.\" --> \"We will implement some code.\")\n",
        "*idea: we can change the target sentences to be specific to a domain*\n",
        "\n",
        "\n",
        "Default: (\"Hll, Wrld\" --> \"Hello, World\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-iHU02C7fAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8aa00fe-3f59-475d-eb44-046e3e137802"
      },
      "source": [
        "import torch\n",
        "import string\n",
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "!pip install unidecode\n",
        "import unidecode\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DIRECTIONS: Aside from the given training data, find one other open-source data. \n",
        "<15 min>\n",
        "\"\"\"\n",
        "# 1. Default training data.\n",
        "!wget https://raw.githubusercontent.com/lorenlugosch/infer_missing_vowels/master/data/train/war_and_peace.txt\n",
        "!pwd\n",
        "\n",
        "# 2. Find a second training dataset.\n",
        "#-----------------------------------------------------------#\n",
        "#\n",
        "# Here I've grabbed a copy of Giant brains; or Machines that think, by Edmund Callis Berkeley.\n",
        "#\n",
        "#-----------------------------------------------------------#\n",
        "!wget https://www.gutenberg.org/cache/epub/68991/pg68991.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "--2022-09-16 03:39:30--  https://raw.githubusercontent.com/lorenlugosch/infer_missing_vowels/master/data/train/war_and_peace.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3196229 (3.0M) [text/plain]\n",
            "Saving to: ‘war_and_peace.txt.4’\n",
            "\n",
            "war_and_peace.txt.4 100%[===================>]   3.05M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-09-16 03:39:30 (67.7 MB/s) - ‘war_and_peace.txt.4’ saved [3196229/3196229]\n",
            "\n",
            "/content\n",
            "--2022-09-16 03:39:30--  https://www.gutenberg.org/cache/epub/68991/pg68991.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 568242 (555K) [text/plain]\n",
            "Saving to: ‘pg68991.txt.4’\n",
            "\n",
            "pg68991.txt.4       100%[===================>] 554.92K  1.56MB/s    in 0.3s    \n",
            "\n",
            "2022-09-16 03:39:32 (1.56 MB/s) - ‘pg68991.txt.4’ saved [568242/568242]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTfRgwxmjv1B"
      },
      "source": [
        "# Building blocks\n",
        "\n",
        "First, we will define the encoder, predictor, and joiner using standard neural nets.\n",
        "\n",
        "<img src=\"https://lorenlugosch.github.io/images/transducer/transducer-model.png\" width=\"25%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7mLFyUG7kJH"
      },
      "source": [
        "\"\"\"\n",
        "RHETORIAL Q: How does changing these numbers affect the performance of the model?\n",
        "In training? In testing? In after-paper performance?\n",
        "\"\"\"\n",
        "\n",
        "NULL_INDEX = 0\n",
        "\n",
        "encoder_dim = 1024\n",
        "predictor_dim = 1024\n",
        "joiner_dim = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MABMTjrGY4vz"
      },
      "source": [
        "The encoder is any network that can take as input a variable-length sequence: so, RNNs, CNNs, and self-attention/Transformer encoders will all work.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE7j2T5EY33-"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, num_inputs):\n",
        "    \"\"\"\n",
        "    @num_inputs: the input size/length\n",
        "\n",
        "    DIRECTIONS: complete the variables for the input_size, hidden_size, and bidirectional arguments in self.rnn\n",
        "    <3 min>\n",
        "    \"\"\"\n",
        "    #-----------------------------------------------------------#\n",
        "    #\n",
        "    # Here we define input_size=encoder_dim, hidden_size=encoder_dim, and bidirectional=True\n",
        "    #\n",
        "    #-----------------------------------------------------------#\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embed = torch.nn.Embedding(num_inputs, encoder_dim)\n",
        "    self.rnn = torch.nn.GRU(input_size=encoder_dim,\n",
        "                            hidden_size=encoder_dim,\n",
        "                            bidirectional=True,\n",
        "                            num_layers=3,\n",
        "                            batch_first=True,\n",
        "                            dropout=0.1)\n",
        "    self.linear = torch.nn.Linear(encoder_dim*2, joiner_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = x\n",
        "    out = self.embed(out)\n",
        "    out = self.rnn(out)[0]\n",
        "    out = self.linear(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRknN6QRY9-g"
      },
      "source": [
        "The predictor is any _causal_ network (= can't look at the future): in other words, unidirectional RNNs, causal convolutions, or masked self-attention. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPARF5LmY7-r"
      },
      "source": [
        "class Predictor(torch.nn.Module):\n",
        "  def __init__(self, num_outputs):\n",
        "    \"\"\"\n",
        "    @num_outputs: the output size/length\n",
        "\n",
        "    DIRECTIONS: complete the variables for the input_size and hidden_size arguments in self.rnn\n",
        "                complete the arguments to torch.nn.Linear in self.linear (hint: 2 required)\n",
        "    <3 min>\n",
        "    \"\"\"\n",
        "    #-----------------------------------------------------------#\n",
        "    #\n",
        "    # Here we define input_size=predictor_dim, hidden_size=predictor_dim\n",
        "    #\n",
        "    # Then we make the two arguments to self.linear the following: predictor_dim, joiner_dim\n",
        "    #\n",
        "    #-----------------------------------------------------------#\n",
        "    super(Predictor, self).__init__()\n",
        "    self.embed = torch.nn.Embedding(num_outputs, predictor_dim)\n",
        "    self.rnn = torch.nn.GRUCell(input_size=predictor_dim,\n",
        "                                hidden_size=predictor_dim)\n",
        "    self.linear = torch.nn.Linear(predictor_dim,\n",
        "                                  joiner_dim)\n",
        "    \n",
        "    self.initial_state = torch.nn.Parameter(torch.randn(predictor_dim))\n",
        "    self.start_symbol = NULL_INDEX # In the original paper, a vector of 0s is used; just using the null index instead is easier when using an Embedding layer.\n",
        "\n",
        "\n",
        "  def forward_one_step(self, input, previous_state):\n",
        "    \"\"\"\n",
        "    This is a helper function for the inherited forward method (since the input may vary).\n",
        "    @input: decoder input\n",
        "    @previous_state: state before passing the input through the RNN's forward method\n",
        "    \"\"\"\n",
        "    embedding = self.embed(input)\n",
        "    state = self.rnn.forward(embedding, previous_state)\n",
        "    out = self.linear(state)\n",
        "    return out, state\n",
        "\n",
        "\n",
        "  def forward(self, y):\n",
        "    \"\"\"\n",
        "    @y: tensor y\n",
        "\n",
        "    DIRECTIONS: complete the variables for batch_size and U (hint: utilize how y is formatted)\n",
        "                complete the variable in the for loop, i.e. replace the 'None'\n",
        "    <5 min>\n",
        "    \"\"\"\n",
        "    #-----------------------------------------------------------#\n",
        "    #\n",
        "    # So, here's a list of the things chnaged in this portion:\n",
        "    #\n",
        "    # batch_size = y.shape[0]\n",
        "    # U = y.shape[1]\n",
        "    # for u in range(U+1):\n",
        "    # \n",
        "    #-----------------------------------------------------------#\n",
        "    batch_size = y.shape[0]\n",
        "    U = y.shape[1] \n",
        "    outs = []\n",
        "    state = torch.stack([self.initial_state] * batch_size).to(y.device)\n",
        "    for u in range(U+1): # hint: we want to get the NULL output for the final timestep \n",
        "      if u == 0:\n",
        "        decoder_input = torch.tensor([self.start_symbol] * batch_size).to(y.device)\n",
        "      else:\n",
        "        decoder_input = y[:,u-1]\n",
        "      out, state = self.forward_one_step(decoder_input, state)\n",
        "      outs.append(out)\n",
        "    out = torch.stack(outs, dim=1)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHPZ3PATZEAW"
      },
      "source": [
        "The joiner is a feedforward network/MLP with one hidden layer applied independently to each $(t,u)$ index.\n",
        "\n",
        "(The linear part of the hidden layer is contained in the encoder and predictor, so we just do the nonlinearity here and then the output layer.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlzca1orZDLa"
      },
      "source": [
        "class Joiner(torch.nn.Module):\n",
        "  def __init__(self, num_outputs):\n",
        "    \"\"\"\n",
        "    @num_outputs: size of softmax output over all labels\n",
        "    \"\"\"\n",
        "    super(Joiner, self).__init__()\n",
        "    self.linear = torch.nn.Linear(joiner_dim, num_outputs)\n",
        "\n",
        "  def forward(self, encoder_out, predictor_out):\n",
        "    \"\"\"\n",
        "    @encoder_out: \n",
        "    @predictor_out: \n",
        "\n",
        "    DIRECTIONS:    choose and apply a nonlinear function of your choice\n",
        "    RHETORICAL Q:  why do we add nonlinearity in a neural network?\n",
        "    <5 min>\n",
        "    \"\"\"\n",
        "    #-----------------------------------------------------------#\n",
        "    #\n",
        "    # The added non-linearity is: torch.nn.functional.relu(out)\n",
        "    # Using other methods to implement RELU not have the softmax method!\n",
        "    #\n",
        "    #-----------------------------------------------------------#\n",
        "    out = encoder_out + predictor_out\n",
        "    out = torch.nn.functional.relu(out)\n",
        "    out = self.linear(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_-INbhSTApv"
      },
      "source": [
        "# Transducer model + loss function\n",
        "\n",
        "Using the encoder, predictor, and joiner, we will implement the Transducer model and its loss function.\n",
        "\n",
        "<img src=\"https://lorenlugosch.github.io/images/transducer/forward-messages.png\" width=\"25%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdcKwA_lkzxJ"
      },
      "source": [
        "We can use a simple PyTorch implementation of the loss function, relying on automatic differentiation to give us gradients."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW9-BGmCI3J0",
        "outputId": "c7569e95-7a82-41f1-e976-54149344f9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "0\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYSagKi-gHM4"
      },
      "source": [
        "class Transducer(torch.nn.Module):\n",
        "  def __init__(self, num_inputs, num_outputs):\n",
        "    super(Transducer, self).__init__()\n",
        "    self.encoder = Encoder(num_inputs)\n",
        "    self.predictor = Predictor(num_outputs)\n",
        "    self.joiner = Joiner(num_outputs)\n",
        "\n",
        "    if torch.cuda.is_available(): self.device = torch.cuda.current_device()\n",
        "    else: self.device = \"cpu\"\n",
        "    self.to(self.device)\n",
        "\n",
        "  def compute_forward_prob(self, joiner_out, T, U, y):\n",
        "    \"\"\"\n",
        "    @joiner_out: tensor of shape (B, T_max, U_max+1, num_labels)\n",
        "    @T: list of input lengths\n",
        "    @U: list of output lengths \n",
        "    @y: label tensor (B, U_max+1)\n",
        "\n",
        "    DIRECTIONS: draw out a couple iterations of the nested for loop below\n",
        "    <15 min>\n",
        "    \"\"\"\n",
        "    #-----------------------------------------------------------#\n",
        "    #\n",
        "    # There's not much to do here, but if you'd like, you can print out\n",
        "    # the values of T and U, 'step' through the loops\n",
        "    #\n",
        "    #-----------------------------------------------------------#\n",
        "    B = joiner_out.shape[0]                                        #B = batch size??\n",
        "    T_max = joiner_out.shape[1]\n",
        "    U_max = joiner_out.shape[2] - 1\n",
        "    log_alpha = torch.zeros(B, T_max, U_max+1).to(model.device)\n",
        "    for t in range(T_max):\n",
        "      for u in range(U_max+1):\n",
        "          if u == 0:\n",
        "            if t == 0:\n",
        "              log_alpha[:, t, u] = 0.\n",
        "\n",
        "            else: #t > 0\n",
        "              log_alpha[:, t, u] = log_alpha[:, t-1, u] + joiner_out[:, t-1, 0, NULL_INDEX] \n",
        "                  \n",
        "          else: #u > 0\n",
        "            if t == 0:\n",
        "              log_alpha[:, t, u] = log_alpha[:, t,u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
        "            \n",
        "            else: #t > 0\n",
        "              log_alpha[:, t, u] = torch.logsumexp(torch.stack([\n",
        "                  log_alpha[:, t-1, u] + joiner_out[:, t-1, u, NULL_INDEX],\n",
        "                  log_alpha[:, t, u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
        "              ]), dim=0)\n",
        "    \n",
        "    log_probs = []\n",
        "    for b in range(B):\n",
        "      log_prob = log_alpha[b, T[b]-1, U[b]] + joiner_out[b, T[b]-1, U[b], NULL_INDEX]\n",
        "      log_probs.append(log_prob)\n",
        "    log_probs = torch.stack(log_probs) \n",
        "    return log_prob # history of logits??\n",
        "\n",
        "  def compute_loss(self, x, y, T, U):\n",
        "    \"\"\"\n",
        "    @x: input/training tensor\n",
        "    @y: label tensor\n",
        "    @T: list of the length of input sequences\n",
        "    @U: list of the length of output sequences\n",
        "    \"\"\"\n",
        "    encoder_out = self.encoder.forward(x)\n",
        "    predictor_out = self.predictor.forward(y)\n",
        "    joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
        "    loss = -self.compute_forward_prob(joiner_out, T, U, y).mean()\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK0c2S2xaARd"
      },
      "source": [
        "Let's first verify that the forward algorithm actually correctly computes the sum (in log space, the [logsumexp](https://lorenlugosch.github.io/posts/2020/06/logsumexp/)) of all possible alignments, using a short input/output pair for which computing all possible alignments is feasible.\n",
        "\n",
        "<img src=\"https://lorenlugosch.github.io/images/transducer/cat-align-1.png\" width=\"25%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWtkoXH6U8Pm"
      },
      "source": [
        "def compute_single_alignment_prob(self, encoder_out, predictor_out, T, U, z, y):\n",
        "    \"\"\"\n",
        "    Computes the probability of one alignment, z.\n",
        "    @encoder_out: Transducer's self.encoder\n",
        "    @predictor_out: Transducer's self.predictor\n",
        "    @T: list of the length of input sequences\n",
        "    @U: list of the length of output sequences\n",
        "    @z: list of 1s and 0s -- the result of our computations to determine\n",
        "        whether or not we should add a null character or label to our prediction\n",
        "        based upon each result from the RNN transducer\n",
        "    @y: label tensor\n",
        "\n",
        "    DIRECTIONS: write a brief description of the argument 'z' above\n",
        "                complete the variables for t_indices and u_indices\n",
        "    <5 min>\n",
        "    \"\"\"\n",
        "    #-----------------------------------------------------------#\n",
        "    #\n",
        "    # Here, we change 'None' to:\n",
        "    # t_indices = [t for (t,u) in t_u_indices]\n",
        "    # u_indices = [u for (t,u) in t_u_indices]\n",
        "    #\n",
        "    #-----------------------------------------------------------#\n",
        "    t = 0; u = 0\n",
        "    t_u_indices = []\n",
        "    y_expanded = []\n",
        "    for step in z:\n",
        "      t_u_indices.append((t,u))\n",
        "      if step == 0: # right (null)\n",
        "        y_expanded.append(NULL_INDEX)\n",
        "        t += 1\n",
        "      if step == 1: # down (label)\n",
        "        y_expanded.append(y[u])\n",
        "        u += 1\n",
        "    t_u_indices.append((T-1,U))\n",
        "    y_expanded.append(NULL_INDEX)\n",
        "\n",
        "    t_indices = [t for (t,u) in t_u_indices]\n",
        "    u_indices = [u for (t,u) in t_u_indices]\n",
        "    encoder_out_expanded = encoder_out[t_indices]\n",
        "    predictor_out_expanded = predictor_out[u_indices]\n",
        "    joiner_out = self.joiner.forward(encoder_out_expanded, predictor_out_expanded).log_softmax(1)\n",
        "    logprob = -torch.nn.functional.nll_loss(input=joiner_out, target=torch.tensor(y_expanded).long().to(self.device), reduction=\"sum\")\n",
        "    return logprob\n",
        "\n",
        "Transducer.compute_single_alignment_prob = compute_single_alignment_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xzM0dZfea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d532dfab-fdb9-410f-f5f5-284b2637e931"
      },
      "source": [
        "# Generate example inputs/outputs\n",
        "num_outputs = len(string.ascii_uppercase) + 1 # [null, A, B, ... Z]\n",
        "model = Transducer(1, num_outputs)\n",
        "y_letters = \"CAT\"\n",
        "y = torch.tensor([string.ascii_uppercase.index(l) + 1 for l in y_letters]).unsqueeze(0).to(model.device)\n",
        "T = torch.tensor([4]); U = torch.tensor([len(y_letters)]); B = 1\n",
        "\n",
        "encoder_out = torch.randn(B, T, joiner_dim).to(model.device)\n",
        "predictor_out = torch.randn(B, U+1, joiner_dim).to(model.device)\n",
        "joiner_out = model.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
        "\n",
        "#######################################################\n",
        "# Compute loss by enumerating all possible alignments #\n",
        "#######################################################\n",
        "all_permutations = list(itertools.permutations([0]*(T-1) + [1]*U))\n",
        "all_distinct_permutations = list(Counter(all_permutations).keys())\n",
        "alignment_probs = []\n",
        "for z in all_distinct_permutations:\n",
        "  alignment_prob = model.compute_single_alignment_prob(encoder_out[0], predictor_out[0], T.item(), U.item(), z, y[0])\n",
        "  alignment_probs.append(alignment_prob)\n",
        "loss_enumerate = -torch.tensor(alignment_probs).logsumexp(0)\n",
        "\n",
        "#######################################################\n",
        "# Compute loss using the forward algorithm            #\n",
        "#######################################################\n",
        "loss_forward = -model.compute_forward_prob(joiner_out, T, U, y)\n",
        "\n",
        "print(\"Loss computed by enumerating all possible alignments: \", loss_enumerate)\n",
        "print(\"Loss computed using the forward algorithm: \", loss_forward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss computed by enumerating all possible alignments:  tensor(24.2673)\n",
            "Loss computed using the forward algorithm:  tensor(24.2673, device='cuda:0', grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSBAwQONf3z9"
      },
      "source": [
        "Now let's add the greedy search algorithm for predicting an output sequence.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "(Note that I've assumed we're using RNNs for the predictor here. You would have to modify this code a bit if you want to use convolutions/self-attention instead.) \n",
        "<br/><br/>\n",
        "<img src=\"https://lorenlugosch.github.io/images/transducer/greedy-search.png\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0xeyb7Jf18_"
      },
      "source": [
        "\"\"\"\n",
        "DIRECTIONS: YOU DO NOT NEED TO IMPLEMENT BEAM SEARCH\n",
        "Here is an *opportunity* to create a beam-search. While the code\n",
        "for a greedy search is here, we can improve this algorithmically! So, you\n",
        "use the greedy search code here to ensure that things are working\n",
        "\n",
        "<might take a while>\n",
        "\"\"\"\n",
        "\n",
        "def greedy_search(self, x, T):\n",
        "  y_batch = []\n",
        "  B = len(x)\n",
        "  encoder_out = self.encoder.forward(x)\n",
        "  U_max = 200\n",
        "  for b in range(B):\n",
        "    t = 0; u = 0; y = [self.predictor.start_symbol]; predictor_state = self.predictor.initial_state.unsqueeze(0)\n",
        "    while t < T[b] and u < U_max:\n",
        "      predictor_input = torch.tensor([ y[-1] ]).to(x.device)\n",
        "      g_u, predictor_state = self.predictor.forward_one_step(predictor_input, predictor_state)\n",
        "      f_t = encoder_out[b, t]\n",
        "      h_t_u = self.joiner.forward(f_t, g_u)\n",
        "      argmax = h_t_u.max(-1)[1].item()\n",
        "      if argmax == NULL_INDEX:\n",
        "        t += 1\n",
        "      else: # argmax == a label\n",
        "        u += 1\n",
        "        y.append(argmax)\n",
        "    y_batch.append(y[1:]) # remove start symbol\n",
        "  return y_batch\n",
        "\n",
        "Transducer.greedy_search = greedy_search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhUQMJ-23f2y",
        "outputId": "40f95e16-eac8-4e0f-850c-23e730980629"
      },
      "source": [
        "!pip install speechbrain\n",
        "from speechbrain.nnet.loss.transducer_loss import TransducerLoss\n",
        "transducer_loss = TransducerLoss(0)\n",
        "\n",
        "def compute_loss(self, x, y, T, U):\n",
        "    encoder_out = self.encoder.forward(x)\n",
        "    predictor_out = self.predictor.forward(y)\n",
        "    joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
        "    #loss = -self.compute_forward_prob(joiner_out, T, U, y).mean()\n",
        "    T = T.to(joiner_out.device)\n",
        "    U = U.to(joiner_out.device)\n",
        "    loss = transducer_loss(joiner_out, y, T, U) #, blank_index=NULL_INDEX, reduction=\"mean\")\n",
        "    return loss\n",
        "\n",
        "Transducer.compute_loss = compute_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.7/dist-packages (0.5.13)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.1.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.9.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.1.97)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.12.1+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.7.3)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.9->speechbrain) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain) (3.0.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.8 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain) (0.17.21)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff9raB0jVGzN"
      },
      "source": [
        "# Some utilities\n",
        "\n",
        "Here we will add a bit of boilerplate code for training and loading data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b17OQm4WdVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968d72e2-7ee2-4495-d858-02ab9f2de8f6"
      },
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, lines, batch_size):\n",
        "    \"\"\"\n",
        "    @lines: list of strings\n",
        "    \"\"\"\n",
        "    lines = list(filter((\"\\n\").__ne__, lines))\n",
        "\n",
        "    self.lines = lines \n",
        "    collate = Collate()\n",
        "    self.loader = torch.utils.data.DataLoader(self, batch_size=batch_size, num_workers=1, shuffle=True, collate_fn=collate)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.lines)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    line = self.lines[idx].replace(\"\\n\", \"\")\n",
        "    line = unidecode.unidecode(line) # remove special characters\n",
        "    x = \"\".join(c for c in line if c not in \"AEIOUaeiou\") # remove vowels from input\n",
        "    y = line\n",
        "    return (x,y)\n",
        "\n",
        "def encode_string(s):\n",
        "  \"\"\"\n",
        "  @s: string\n",
        "  \"\"\"\n",
        "  for c in s:\n",
        "    if c not in string.printable:\n",
        "      print(s)\n",
        "  return [string.printable.index(c) + 1 for c in s]\n",
        "\n",
        "def decode_labels(l):\n",
        "  \"\"\"\n",
        "  @l: list of labels\n",
        "  \"\"\"\n",
        "  return \"\".join([string.printable[c - 1] for c in l])\n",
        "\n",
        "\n",
        "class Collate:\n",
        "  def __call__(self, batch):\n",
        "    \"\"\"\n",
        "    Returns a minibatch of strings, encoded as labels and padded to have the same length.\n",
        "    @batch: list of tuples (input string, output string)\n",
        "\n",
        "    DIRECTIONS: after obtaining results from training on the default text, train on your second training text \n",
        "    <10 min>\n",
        "    \"\"\"\n",
        "    #-----------------------------------------------------------#\n",
        "    #\n",
        "    # Here, all we have to do is change war_and_peace.txt to our chosen file\n",
        "    # Note here - we actually want to \n",
        "    #\n",
        "    #-----------------------------------------------------------#\n",
        "    x = []; y = []\n",
        "    batch_size = len(batch)\n",
        "    for index in range(batch_size):\n",
        "      x_,y_ = batch[index]\n",
        "      x.append(encode_string(x_))\n",
        "      y.append(encode_string(y_))\n",
        "\n",
        "    # pad all sequences to have same length\n",
        "    T = [len(x_) for x_ in x]\n",
        "    U = [len(y_) for y_ in y]\n",
        "    T_max = max(T)\n",
        "    U_max = max(U)\n",
        "    for index in range(batch_size):\n",
        "      x[index] += [NULL_INDEX] * (T_max - len(x[index]))\n",
        "      x[index] = torch.tensor(x[index])\n",
        "      y[index] += [NULL_INDEX] * (U_max - len(y[index]))\n",
        "      y[index] = torch.tensor(y[index])\n",
        "\n",
        "    # stack into single tensor\n",
        "    x = torch.stack(x)\n",
        "    y = torch.stack(y)\n",
        "    T = torch.tensor(T)\n",
        "    U = torch.tensor(U)\n",
        "\n",
        "    return (x,y,T,U)\n",
        "\n",
        "with open(\"pg68991.txt.3\", \"r\") as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "end = round(0.9 * len(lines))\n",
        "train_lines = lines[:end]\n",
        "test_lines = lines[end:]\n",
        "train_set = TextDataset(train_lines, batch_size=64) #8)\n",
        "test_set = TextDataset(test_lines, batch_size=64) #8)\n",
        "train_set.__getitem__(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Th Prjct Gtnbrg Bk f Gnt brns; r Mchns tht thnk,',\n",
              " 'The Project Gutenberg eBook of Giant brains; or Machines that think,')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaZEQYzfFEQ0"
      },
      "source": [
        "class Trainer:\n",
        "  def __init__(self, model, lr):\n",
        "    self.model = model\n",
        "    self.lr = lr\n",
        "    self.optimizer = torch.optim.Adam(model.parameters(), lr=self.lr)\n",
        "  \n",
        "  def train(self, dataset, print_interval = 20):\n",
        "    train_loss = 0\n",
        "    num_samples = 0\n",
        "    self.model.train()\n",
        "    pbar = tqdm(dataset.loader)\n",
        "    for idx, batch in enumerate(pbar):\n",
        "      x,y,T,U = batch\n",
        "      x = x.to(self.model.device); y = y.to(self.model.device)\n",
        "      batch_size = len(x)\n",
        "      num_samples += batch_size\n",
        "      loss = self.model.compute_loss(x,y,T,U)\n",
        "      self.optimizer.zero_grad()\n",
        "      pbar.set_description(\"%.2f\" % loss.item())\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "      train_loss += loss.item() * batch_size\n",
        "      if idx % print_interval == 0:\n",
        "        self.model.eval()\n",
        "        guesses = self.model.greedy_search(x,T)\n",
        "        self.model.train()\n",
        "        print(\"\\n\")\n",
        "        for b in range(2):\n",
        "          print(\"input:\", decode_labels(x[b,:T[b]]))\n",
        "          print(\"guess:\", decode_labels(guesses[b]))\n",
        "          print(\"truth:\", decode_labels(y[b,:U[b]]))\n",
        "          print(\"\")\n",
        "    train_loss /= num_samples\n",
        "    return train_loss\n",
        "\n",
        "  def test(self, dataset, print_interval=1):\n",
        "    test_loss = 0\n",
        "    num_samples = 0\n",
        "    self.model.eval()\n",
        "    pbar = tqdm(dataset.loader)\n",
        "    for idx, batch in enumerate(pbar):\n",
        "      x,y,T,U = batch\n",
        "      x = x.to(self.model.device); y = y.to(self.model.device)\n",
        "      batch_size = len(x)\n",
        "      num_samples += batch_size\n",
        "      loss = self.model.compute_loss(x,y,T,U)\n",
        "      pbar.set_description(\"%.2f\" % loss.item())\n",
        "      test_loss += loss.item() * batch_size\n",
        "      if idx % print_interval == 0:\n",
        "        print(\"\\n\")\n",
        "        print(\"input:\", decode_labels(x[0,:T[0]]))\n",
        "        print(\"guess:\", decode_labels(self.model.greedy_search(x,T)[0]))\n",
        "        print(\"truth:\", decode_labels(y[0,:U[0]]))\n",
        "        print(\"\")\n",
        "    test_loss /= num_samples\n",
        "    return test_loss\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4PupgBKWe6p"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "Now we will train a model. This will generate some output sequences every 20 batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TSrbH9xGPEC"
      },
      "source": [
        "#-----------------------------------------------------------#\n",
        "#\n",
        "# At this point, your colab notebook *should* be workable.\n",
        "#\n",
        "# If you encounter these errors, try these solutions which worked for me:\n",
        "# ERROR:\n",
        "# \"ValueError: Found inputs tensors to be on [device(type='cuda', index=0),\n",
        "#                                               device(type='cuda', index=0),\n",
        "#               `                               device(type='cuda', index=0),\n",
        "#                                               device(type='cuda', index=0)]\n",
        "#   while needed to be on a 'cuda' device to use the transducer loss\"\n",
        "# SOLUTION:\n",
        "# Go back to the cell with the first line: 'class Transducer(torch.nn.Module):',\n",
        "# and rerun that cell. Now, try rerunning this cell.\n",
        "#\n",
        "# ERROR:\n",
        "# AttributeError: 'Transducer' object has no attribute 'greedy_search'\n",
        "# SOLUTION:\n",
        "# Go back to the cell with the first line: 'def greedy_search(self, x, T):',\n",
        "# and rerun that cell, Now, try rerunning this cell.\n",
        "#\n",
        "# After getting both errors above and fixing them, the cell said it would train\n",
        "# for a few hours, which is a surprisingly long amount\n",
        "# of time - I thought it went much faster when I hadn't been getting those errors\n",
        "#. If you would like to try running this on a TPU, good luck!\n",
        "#\n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "num_chars = len(string.printable)\n",
        "model = Transducer(num_inputs=num_chars+1, num_outputs=num_chars+1)\n",
        "trainer = Trainer(model=model, lr=0.0003)\n",
        "\n",
        "num_epochs = 1\n",
        "train_losses=[]\n",
        "test_losses=[]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = trainer.train(train_set)\n",
        "    test_loss = trainer.test(test_set)\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    print(\"Epoch %d: train loss = %f, test loss = %f\" % (epoch, train_loss, test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRahAWPoubyu"
      },
      "source": [
        "print(train_losses)\n",
        "print(test_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLQKw4kmFj3S"
      },
      "source": [
        "Let's test the model on a new sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhH5lYdyEazJ"
      },
      "source": [
        "\"\"\"\n",
        "DIRECTIONS: Experiment with different test outputs. What are some things to keep in mind when changing the test outputs?\n",
        "<5 min>\n",
        "\"\"\"\n",
        "#-----------------------------------------------------------#\n",
        "#\n",
        "# Feel free to try it as you see fit!\n",
        "#\n",
        "#-----------------------------------------------------------#\n",
        "test_output = \"Most people have little difficulty reading this sentence\"\n",
        "test_input = \"\".join(c for c in test_output if c not in \"AEIOUaeiou\")\n",
        "print(\"input: \" + test_input)\n",
        "x = torch.tensor(encode_string(test_input)).unsqueeze(0).to(model.device)\n",
        "y = torch.tensor(encode_string(test_output)).unsqueeze(0).to(model.device)\n",
        "T = torch.tensor([x.shape[1]]).to(model.device)\n",
        "U = torch.tensor([y.shape[1]]).to(model.device)\n",
        "guess = model.greedy_search(x,T)[0]\n",
        "print(\"truth: \" + test_output)\n",
        "print(\"guess: \" + decode_labels(guess))\n",
        "print(\"\")\n",
        "y_guess = torch.tensor(guess).unsqueeze(0).to(model.device)\n",
        "U_guess = torch.tensor(len(guess)).unsqueeze(0).to(model.device)\n",
        "\n",
        "print(\"NLL of truth: \" + str(model.compute_loss(x, y, T, U)))\n",
        "print(\"NLL of guess: \" + str(model.compute_loss(x, y_guess, T, U_guess)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET__-ItZD8eA"
      },
      "source": [
        "Observe that the negative log-likelihood of the guess is actually worse than that of the true label sequence (AKA, a \"[search error](https://www.aclweb.org/anthology/D19-1331.pdf)\"). This suggests that we could get better results using a beam search instead of the greedy search."
      ]
    }
  ]
}